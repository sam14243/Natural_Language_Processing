{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Links to go through\n",
    "- https://www.youtube.com/results?search_query=spell+check+using+trie\n",
    "- https://medium.com/@yashj302/spell-check-and-correction-nlp-python-f6a000e3709d\n",
    "- https://www.scaler.com/topics/nlp/create-a-spell-check-with-nlp/\n",
    "- https://www.geeksforgeeks.org/correcting-words-using-nltk-in-python/\n",
    "- https://www.youtube.com/watch?v=OIJBKqzrlX0\n",
    "- https://medium.com/@surmenok/deep-learning-for-spell-checking-2ffdbad65554#:~:text=Just%20create%20artificial%20dataset%20by,errors%20to%20a%20correct%20text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First Attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.util import ngrams\n",
    "from nltk.metrics.distance import edit_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = {\n",
    "    \"Mr Patrick is our new xyz.\": [\"principal\", \"principle\"],\n",
    "    \"The company xyz all the terms.\": [\"accepted\", \"excepted\"],\n",
    "    \"Please don’t keep your dog on the xyz.\": [\"loose\", \"lose\"],\n",
    "    \"The xyz is my best friend.\": [\"latter\", \"later\"],\n",
    "    \"I need some xyz products for my craftwork.\": [\"stationery\", \"stationary\"],\n",
    "    \"The actor xyz the Oscar.\": [\"accepted\", \"excepted\"],\n",
    "    \"I will call you xyz in the evening.\": [\"later\", \"latter\"],\n",
    "    \"Covid xyz the lungs.\": [\"affects\", \"effects\"],\n",
    "    \"The xyz of the ministers were sworn in yesterday.\": [\"council\", \"counsel\"],\n",
    "    \"Robert xyz wants to accompany us to the park.\": [\"too\", \"to\"],\n",
    "    \"Mia will xyz me about choosing fashion as my career.\": [\"counsel\", \"council\"],\n",
    "    \"The xyz at the zoo was very playful.\": [\"bear\", \"bare\"],\n",
    "    \"The sheep have a lot of xyz that keeps them warm.\": [\"fur\", \"far\"], \"The hot spring is at the xyz corner of the street.\": [\"farthest\", \"furthest\"],\n",
    "    \"Can you xyz me on how to study for exams?\": [\"advise\", \"advice\"],\n",
    "    \"The team will xyz the match if they don’t play well.\": [\"lose\", \"loose\"], \"Can you go xyz the market for me?\": [\"to\", \"too\"],\n",
    "    \"The teachers asked the students to keep xyz.\": [\"quiet\", \"quite\"],\n",
    "    \"The xyz of garbage should be cleaned immediately.\": [\"heap\", \"hip\"], \n",
    "    \"This is xyz house.\": [\"their\", \"there\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_fit_word(sentence, choices):\n",
    "    n = len(sentence.split())\n",
    "    sentence_ngrams = list(ngrams(sentence.split(), n))\n",
    "    best_fit_word = None\n",
    "    min_distance = float('inf') \n",
    "    for choice in choices:\n",
    "        choice_ngrams = list(ngrams(choice.split(), n))\n",
    "        distance = edit_distance(sentence_ngrams, choice_ngrams) \n",
    "        if distance < min_distance:\n",
    "            min_distance = distance\n",
    "            best_fit_word = choice \n",
    "    return best_fit_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "for sentence, choices in sentences.items():\n",
    "    best_fit_word = find_best_fit_word(sentence, choices)\n",
    "    results[sentence] = best_fit_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mr Patrick is our new principal.\n",
      "The company accepted all the terms.\n",
      "Please don’t keep your dog on the loose.\n",
      "The latter is my best friend.\n",
      "I need some stationery products for my craftwork.\n",
      "The actor accepted the Oscar.\n",
      "I will call you later in the evening.\n",
      "Covid affects the lungs.\n",
      "The council of the ministers were sworn in yesterday.\n",
      "Robert too wants to accompany us to the park.\n",
      "Mia will counsel me about choosing fashion as my career.\n",
      "The bear at the zoo was very playful.\n",
      "The sheep have a lot of fur that keeps them warm.\n",
      "The hot spring is at the farthest corner of the street.\n",
      "Can you advise me on how to study for exams?\n",
      "The team will lose the match if they don’t play well.\n",
      "Can you go to the market for me?\n",
      "The teachers asked the students to keep quiet.\n",
      "The heap of garbage should be cleaned immediately.\n",
      "This is their house.\n"
     ]
    }
   ],
   "source": [
    "for sentence, best_fit_word in results.items(): \n",
    "    print(sentence.replace('xyz', best_fit_word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Tries for Context Words (Given a sentence, find the correct spelling)\n",
    "[From Here](https://github.com/LaVivien/SpellingCorrector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Distance Metrics for Individual Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textdistance in /Users/daver/Desktop/College Work/NLP_Lab_Exam_Codes/.venv/lib/python3.12/site-packages (4.6.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%pip install textdistance\n",
    "import textdistance\n",
    "import re\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Unique words are :  {17647}\n"
     ]
    }
   ],
   "source": [
    "words = []\n",
    "with open('./resources/spelling_correction.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        words.extend(re.findall(r'\\w+', line.lower()))\n",
    "\n",
    "\n",
    "# This is our vocabulary\n",
    "V = set(words)\n",
    "# print(\"Top ten words in the text are:\", {words[0:10]})\n",
    "print(\"Total Unique words are : \", {len(V)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 14703), ('of', 6742), ('and', 6517), ('a', 4799), ('to', 4707), ('in', 4238), ('that', 3081), ('it', 2534), ('his', 2530), ('i', 2120)]\n"
     ]
    }
   ],
   "source": [
    "# Word Frequency Counter\n",
    "word_freq = {}  \n",
    "word_freq = Counter(words)\n",
    "print(word_freq.most_common()[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relative Frequency of Words\n",
    "probs = {}     \n",
    "Total = sum(word_freq.values())    \n",
    "for k in word_freq.keys():\n",
    "    probs[k] = word_freq[k]/Total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort Similar Words according to Jaccard Distance\n",
    "def my_autocorrect(input_word):\n",
    "    input_word = input_word.lower()\n",
    "    if input_word in V:\n",
    "        return('Your word seems to be correct')\n",
    "    else:\n",
    "        sim = [1-(textdistance.Jaccard(qval=2).distance(v,input_word)) for v in word_freq.keys()]\n",
    "        df = pd.DataFrame.from_dict(probs, orient='index').reset_index()\n",
    "        df = df.rename(columns={'index':'Word', 0:'Prob'})\n",
    "        df['Similarity'] = sim\n",
    "        output = df.sort_values(['Similarity', 'Prob'], ascending=False).head()\n",
    "        return(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Prob</th>\n",
       "      <th>Similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2571</th>\n",
       "      <td>nevertheless</td>\n",
       "      <td>0.000225</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13657</th>\n",
       "      <td>boneless</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12684</th>\n",
       "      <td>elevates</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1105</th>\n",
       "      <td>never</td>\n",
       "      <td>0.000925</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7136</th>\n",
       "      <td>level</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Word      Prob  Similarity\n",
       "2571   nevertheless  0.000225    0.750000\n",
       "13657      boneless  0.000013    0.416667\n",
       "12684      elevates  0.000004    0.416667\n",
       "1105          never  0.000925    0.400000\n",
       "7136          level  0.000108    0.400000"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_autocorrect('neverteless')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
