{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5d7e83d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "283433a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"labeled_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc86577b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ee6366d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 24783 entries, 0 to 24782\n",
      "Data columns (total 7 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   Unnamed: 0          24783 non-null  int64 \n",
      " 1   count               24783 non-null  int64 \n",
      " 2   hate_speech         24783 non-null  int64 \n",
      " 3   offensive_language  24783 non-null  int64 \n",
      " 4   neither             24783 non-null  int64 \n",
      " 5   class               24783 non-null  int64 \n",
      " 6   tweet               24783 non-null  object\n",
      "dtypes: int64(6), object(1)\n",
      "memory usage: 1.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93ab5e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['Unnamed: 0','count', 'hate_speech', 'offensive_language', 'neither'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09100044",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tweet']= df['tweet'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d17aac6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>!!! rt @mayasolovely: as a woman you shouldn't...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>!!!!! rt @mleew17: boy dats cold...tyga dwn ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!! rt @urkindofbrand dawg!!!! rt @80sbaby...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!! rt @c_g_anderson: @viva_based she lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!!!!!! rt @shenikaroberts: the shit you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24778</th>\n",
       "      <td>1</td>\n",
       "      <td>you's a muthaf***in lie &amp;#8220;@lifeasking: @2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24779</th>\n",
       "      <td>2</td>\n",
       "      <td>you've gone and broke the wrong heart baby, an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24780</th>\n",
       "      <td>1</td>\n",
       "      <td>young buck wanna eat!!.. dat nigguh like i ain...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24781</th>\n",
       "      <td>1</td>\n",
       "      <td>youu got wild bitches tellin you lies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24782</th>\n",
       "      <td>2</td>\n",
       "      <td>~~ruffled | ntac eileen dahlia - beautiful col...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24783 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       class                                              tweet\n",
       "0          2  !!! rt @mayasolovely: as a woman you shouldn't...\n",
       "1          1  !!!!! rt @mleew17: boy dats cold...tyga dwn ba...\n",
       "2          1  !!!!!!! rt @urkindofbrand dawg!!!! rt @80sbaby...\n",
       "3          1  !!!!!!!!! rt @c_g_anderson: @viva_based she lo...\n",
       "4          1  !!!!!!!!!!!!! rt @shenikaroberts: the shit you...\n",
       "...      ...                                                ...\n",
       "24778      1  you's a muthaf***in lie &#8220;@lifeasking: @2...\n",
       "24779      2  you've gone and broke the wrong heart baby, an...\n",
       "24780      1  young buck wanna eat!!.. dat nigguh like i ain...\n",
       "24781      1              youu got wild bitches tellin you lies\n",
       "24782      2  ~~ruffled | ntac eileen dahlia - beautiful col...\n",
       "\n",
       "[24783 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a9cc5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "stopwords = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee49d22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "wordnet_lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e16449cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(text):\n",
    "    output = \" \".join([i for i in text.split() if i not in stopwords])\n",
    "    punctuationfree = \"\".join([i for i in output if i not in string.punctuation])\n",
    "    lemm_text = \" \".join([wordnet_lemmatizer.lemmatize(word) for word in punctuationfree.split()])\n",
    "    return lemm_text\n",
    "\n",
    "df['tweet']= df['tweet'].apply(lambda x:preprocessing(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f2c86a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "a0f88233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting gensim\n",
      "  Downloading gensim-4.3.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 26.6 MB 12.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scipy>=1.7.0 in /opt/anaconda3/lib/python3.9/site-packages (from gensim) (1.7.1)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /opt/anaconda3/lib/python3.9/site-packages (from gensim) (1.22.4)\n",
      "Collecting smart-open>=1.8.1\n",
      "  Downloading smart_open-6.4.0-py3-none-any.whl (57 kB)\n",
      "\u001b[K     |████████████████████████████████| 57 kB 1.0 MB/s  eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: smart-open, gensim\n",
      "Successfully installed gensim-4.3.2 smart-open-6.4.0\n"
     ]
    }
   ],
   "source": [
    "# !pip install gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afcd2243",
   "metadata": {},
   "source": [
    "### Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1132e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import gensim\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7311e593",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '. '.join(df['tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e12cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "16bce5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for i in sent_tokenize(text):\n",
    "    temp = []\n",
    "    # tokenize the sentence into words\n",
    "    for j in word_tokenize(i):\n",
    "        temp.append(j.lower())\n",
    "    data.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11bd8070",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f7c79b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = gensim.models.Word2Vec(data, min_count=1,\n",
    "                                vector_size=100, window=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b0f33168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec<vocab=39151, vector_size=100, alpha=0.025>\n"
     ]
    }
   ],
   "source": [
    "print(model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "34bbb501",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = gensim.models.FastText(data, vector_size=100, window=5, min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ebf72c8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.0429167e+00,  1.8856901e+00, -1.2663317e-01, -2.2378220e-01,\n",
       "        5.2460223e-01, -4.7055796e-01,  9.1117585e-01,  1.0626067e+00,\n",
       "        1.3137904e+00, -1.3334157e+00, -4.9269298e-01,  3.3759028e-01,\n",
       "       -1.5613754e+00,  2.4414299e+00, -8.6124569e-01,  5.6652683e-01,\n",
       "        5.3977221e-01,  2.1900105e-01,  9.3020517e-03, -1.8471794e+00,\n",
       "       -1.3062351e+00,  9.6717548e-01, -3.4825140e-01,  6.4869243e-01,\n",
       "       -1.2568403e+00, -3.3689046e-01, -7.4688351e-01,  1.2027250e-01,\n",
       "        2.1966293e+00, -1.2843390e+00, -7.3803532e-01, -1.4432801e-01,\n",
       "        1.1612551e+00, -4.0326198e-03,  2.1145828e-01,  1.2964697e-01,\n",
       "        5.6547129e-01,  8.1161278e-01, -1.9541128e+00,  5.6700606e-02,\n",
       "        7.5918353e-01, -1.3986348e-01,  5.3739446e-01, -1.7368630e+00,\n",
       "        3.9722580e-01,  5.2114107e-02, -1.2709125e+00, -8.8171762e-01,\n",
       "       -3.7032459e-02,  3.7594754e-01,  7.2564739e-01, -6.3473684e-01,\n",
       "        1.0126089e+00, -6.2753427e-01, -1.7840202e-01, -2.0798226e-01,\n",
       "        3.7304139e-01,  1.9411844e+00,  1.2889566e-01,  3.4913898e-01,\n",
       "       -9.5682308e-02, -8.0506647e-01, -1.2384377e+00,  1.9222887e+00,\n",
       "        8.3645344e-01,  2.1780090e+00, -6.7818001e-02, -7.3778574e-05,\n",
       "        3.8440165e-01,  2.5956404e-01,  1.4007585e-01,  8.4459263e-01,\n",
       "       -2.0282997e-02, -2.1529536e-01,  2.4796404e-01,  1.5098287e+00,\n",
       "       -1.2248250e-01,  7.2961755e-02, -2.3968561e-02,  5.4191929e-01,\n",
       "       -2.4290003e-01,  4.2616600e-01,  9.2734873e-01,  2.1696691e-01,\n",
       "       -1.0143931e+00, -1.3245763e+00, -1.4463061e+00, -7.1275616e-01,\n",
       "       -2.3114125e-01, -3.3830991e-01, -1.2555739e+00,  1.1890054e-01,\n",
       "        9.6169926e-02, -2.2076787e-02, -2.1758773e+00,  1.1961758e+00,\n",
       "       -1.6939010e-01, -1.2646348e+00,  5.7009077e-01,  9.4776165e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.wv.get_vector('bad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29404262",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tweet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fcb33743",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn.utils.rnn import pad_sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec21a61",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "81218735",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [\"<PAD>\"]\n",
    "x = []\n",
    "for sent in df['tweet']:\n",
    "    tmp = []\n",
    "    for w in sent.split(' '):\n",
    "        if w not in words:\n",
    "            words.append(w)\n",
    "        tmp.append(words.index(w))\n",
    "    x.append(torch.tensor(tmp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a187454b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([24783, 30])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = pad_sequence(x, batch_first=True, padding_value=0)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "24a99cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, vocab_dim):\n",
    "        super(CNN, self).__init__()\n",
    "        emb_dim = 100\n",
    "        self.emb = nn.Embedding(vocab_dim, emb_dim)\n",
    "        self.conv = nn.Conv1d(emb_dim, 64, 3)\n",
    "        self.pool = nn.AdaptiveMaxPool1d(1)\n",
    "        self.fc = nn.Linear(64, 2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.emb(x)\n",
    "        x = self.conv(x.permute(0,2,1))\n",
    "        x = self.pool(torch.relu(x)).squeeze(2)\n",
    "        x = self.fc(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e1aeea3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = CNN(len(words))\n",
    "out = mod(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3f4cbfd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([24783, 2])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e836a016",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['class'].copy()\n",
    "y[y==2] = 1\n",
    "y = torch.from_numpy(pd.get_dummies(y).values)\n",
    "y = y.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5aba5062",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        ...,\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "32b47b8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0  loss: tensor(0.6703, grad_fn=<BinaryCrossEntropyBackward0>) prediction: tensor([[0.4083, 0.3638],\n",
      "        [0.4600, 0.4696],\n",
      "        [0.4371, 0.5107],\n",
      "        [0.3513, 0.5809],\n",
      "        [0.4477, 0.4821]], grad_fn=<SliceBackward0>)\n",
      "epoch: 1  loss: tensor(0.2396, grad_fn=<BinaryCrossEntropyBackward0>) prediction: tensor([[0.1505, 0.8561],\n",
      "        [0.2299, 0.8778],\n",
      "        [0.1116, 0.9163],\n",
      "        [0.1295, 0.9495],\n",
      "        [0.1269, 0.9142]], grad_fn=<SliceBackward0>)\n",
      "epoch: 2  loss: tensor(0.2617, grad_fn=<BinaryCrossEntropyBackward0>) prediction: tensor([[0.0164, 0.9889],\n",
      "        [0.0242, 0.9901],\n",
      "        [0.0099, 0.9935],\n",
      "        [0.0132, 0.9954],\n",
      "        [0.0099, 0.9936]], grad_fn=<SliceBackward0>)\n",
      "epoch: 3  loss: tensor(0.3042, grad_fn=<BinaryCrossEntropyBackward0>) prediction: tensor([[0.0067, 0.9961],\n",
      "        [0.0089, 0.9965],\n",
      "        [0.0036, 0.9981],\n",
      "        [0.0061, 0.9985],\n",
      "        [0.0036, 0.9981]], grad_fn=<SliceBackward0>)\n",
      "epoch: 4  loss: tensor(0.2946, grad_fn=<BinaryCrossEntropyBackward0>) prediction: tensor([[0.0062, 0.9961],\n",
      "        [0.0082, 0.9965],\n",
      "        [0.0032, 0.9984],\n",
      "        [0.0069, 0.9986],\n",
      "        [0.0035, 0.9984]], grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(mod.parameters(), lr=0.01)\n",
    "for epoch in range(5):\n",
    "    mod.train()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    out = mod(x)\n",
    "    loss = criterion(out, y)\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    print(\"epoch:\",epoch, \" loss:\", loss, \"prediction:\", out[:5,:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "49e0aa27",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = np.argmax(y, axis=1)\n",
    "y_pred = np.argmax(out.detach().numpy(), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8af8602a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9422991566799822"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_pred, y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42365107",
   "metadata": {},
   "source": [
    "### RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "74405d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, vocab_dim, seq_len):\n",
    "        super(RNN, self).__init__()\n",
    "        emb_dim = 100\n",
    "        self.emb = nn.Embedding(vocab_dim, emb_dim)\n",
    "        self.rnn = nn.RNN(emb_dim, 100)\n",
    "        self.fc = nn.Linear(100, 2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.emb(x)\n",
    "        _,x = self.rnn(x.permute(1,0,2))\n",
    "        x = self.fc(x).squeeze(0)\n",
    "        return torch.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ccb5520d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([24783, 2])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod = RNN(len(words), x.shape[1])\n",
    "out = mod(x)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "209aec94",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(mod.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "8e955e5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0  loss: tensor(0.6396, grad_fn=<BinaryCrossEntropyBackward0>) prediction: tensor([[0.4988, 0.5636],\n",
      "        [0.4988, 0.5636],\n",
      "        [0.4988, 0.5636],\n",
      "        [0.4988, 0.5636],\n",
      "        [0.4988, 0.5636]], grad_fn=<SliceBackward0>)\n",
      "epoch: 1  loss: tensor(0.2413, grad_fn=<BinaryCrossEntropyBackward0>) prediction: tensor([[0.0714, 0.8530],\n",
      "        [0.0714, 0.8530],\n",
      "        [0.0714, 0.8530],\n",
      "        [0.0714, 0.8530],\n",
      "        [0.0714, 0.8530]], grad_fn=<SliceBackward0>)\n",
      "epoch: 2  loss: tensor(0.2212, grad_fn=<BinaryCrossEntropyBackward0>) prediction: tensor([[0.0580, 0.9532],\n",
      "        [0.0580, 0.9532],\n",
      "        [0.0580, 0.9532],\n",
      "        [0.0580, 0.9532],\n",
      "        [0.0580, 0.9532]], grad_fn=<SliceBackward0>)\n",
      "epoch: 3  loss: tensor(0.2261, grad_fn=<BinaryCrossEntropyBackward0>) prediction: tensor([[0.0484, 0.9696],\n",
      "        [0.0484, 0.9696],\n",
      "        [0.0484, 0.9696],\n",
      "        [0.0484, 0.9696],\n",
      "        [0.0484, 0.9696]], grad_fn=<SliceBackward0>)\n",
      "epoch: 4  loss: tensor(0.2279, grad_fn=<BinaryCrossEntropyBackward0>) prediction: tensor([[0.0444, 0.9721],\n",
      "        [0.0444, 0.9721],\n",
      "        [0.0444, 0.9721],\n",
      "        [0.0444, 0.9721],\n",
      "        [0.0444, 0.9721]], grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(5):\n",
    "    mod.train()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    out = mod(x)\n",
    "    loss = criterion(out, y)\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    print(\"epoch:\",epoch, \" loss:\", loss, \"prediction:\", out[:5,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9037428c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = np.argmax(y, axis=1)\n",
    "y_pred = np.argmax(out.detach().numpy(), axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
